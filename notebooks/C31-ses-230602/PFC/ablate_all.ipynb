{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23ee8b4-0dfa-41eb-b05e-9f83331cff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/surprisal_regression\n"
     ]
    }
   ],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e01a5a-e6dc-43b5-bf28-d388b107aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import math\n",
    "from omegaconf import OmegaConf\n",
    "import pyro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cb4db0-90d6-4f00-8fb7-a072c7aed6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.linear_regression import TrialwiseLinearRegression\n",
    "import src.eval as evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9702f7-ac7a-4306-b594-adaa70198cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] No logger configs found! Skipping...\n",
      "[striatum:816069] shmem: mmap: an error occurred while determining whether or not /tmp/ompi.striatum.1000/jf.0/4217241600/shared_mem_cuda_pool.striatum could be created.\n",
      "[striatum:816069] create_and_attach: unable to create shared memory BTL coordinating structure :: size 134217728 \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at logs/train/runs/2025-04-01_07-47-24/checkpoints/last.ckpt\n",
      "/home/eli/miniforge3/envs/ephys/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\", \"EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}\"].\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at logs/train/runs/2025-04-01_07-47-24/checkpoints/last.ckpt\n",
      "/home/eli/miniforge3/envs/ephys/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/eli/miniforge3/envs/ephys/lib/python3.12/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dd3e242bd841c082ae822bbd6d28aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/log_evidence     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -3100.114990234375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/log_likelihood    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -16.822805404663086    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4521.53564453125      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/log_evidence    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -3100.114990234375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/log_likelihood   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -16.822805404663086   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4521.53564453125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with hydra.initialize(version_base=\"1.3\", config_path=\"../../../configs\", job_name=\"eval\"):\n",
    "    cfg = hydra.compose(config_name=\"eval.yaml\", overrides=[\"ckpt_path=logs/train/runs/2025-04-01_07-47-24/checkpoints/last.ckpt\", \"data.session_path=/mnt/data/surprisal_coding/epoched/glo_mua_epoched_9.mat\",\n",
    "                        \"data.area=PFC\", \"model.importance.ablations=['surprise','repetition']\"], return_hydra_config=True)\n",
    "    hydra.core.hydra_config.HydraConfig.instance().set_config(cfg)\n",
    "    _, objects = evaluation.evaluate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36740ee-edde-4b34-8295-96a114b4fa8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m regressor \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m rvs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, (muae, regressors) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28menumerate\u001b[39m(objects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatamodule\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtest_dataloader())):\n\u001b[1;32m      8\u001b[0m     _, predictions, _, trace \u001b[38;5;241m=\u001b[39m objects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmodel_step((muae, regressors))\n\u001b[1;32m     10\u001b[0m     originals\u001b[38;5;241m.\u001b[39mappend(muae)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    originals = []\n",
    "    reconstructions = []\n",
    "    regressor = []\n",
    "    rvs = {}\n",
    "    \n",
    "    for b, (muae, regressors) in tqdm(enumerate(objects['datamodule'].test_dataloader())):\n",
    "        _, predictions, _, trace = objects['model'].model_step((muae, regressors))\n",
    "    \n",
    "        originals.append(muae)\n",
    "        reconstructions.append(predictions.mean(dim=0))\n",
    "        regressor.append(regressors)\n",
    "        for rv in trace.nodes:\n",
    "            if trace.nodes[rv]['type'] == 'sample':\n",
    "                if rv in rvs:\n",
    "                    rvs[rv] = torch.cat((rvs[rv], trace.nodes[rv]['value']), dim=1)\n",
    "                else:\n",
    "                    rvs[rv] =  trace.nodes[rv]['value']\n",
    "\n",
    "\n",
    "    originals = torch.cat(originals, dim=0)\n",
    "    reconstructions = torch.cat(reconstructions, dim=0)\n",
    "    regressors = torch.cat(regressor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec2335-f9bd-4921-be92-6799dd3570e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lo_trials():\n",
    "    return torch.isclose(regressors[:, :, 3], -torch.tensor([[1, 1, 1, 0.8]], dtype=torch.double).log2()).all(dim=-1).argwhere().flatten(0, 1)\n",
    "\n",
    "def go_trials():\n",
    "    return torch.isclose(regressors[:, :, 3], -torch.tensor([[1, 1, 1, 0.2]], dtype=torch.double).log2()).all(dim=-1).argwhere().flatten(0, 1)\n",
    "\n",
    "def rndctrl_trials():\n",
    "    return torch.isclose(regressors[:, :, 3], -torch.tensor([[0.5, 0.5, 0.5, 0.5]], dtype=torch.double).log2()).all(dim=-1).argwhere().flatten(0, 1)\n",
    "\n",
    "def seqctrl_trials():\n",
    "    return torch.isclose(regressors[:, :, 3], -torch.tensor([[1., 1., 1., 1.]], dtype=torch.double).log2()).all(dim=-1).argwhere().flatten(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bdf15-1f30-4ce6-b694-2b558a20a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(trials):\n",
    "    heights = []\n",
    "    all_originals = originals[trials, :].mean(dim=0)\n",
    "    all_reconstructions = reconstructions[trials, :].mean(dim=0)\n",
    "\n",
    "    for p in range(4):\n",
    "        heights = heights + [all_originals[p].item(), all_reconstructions[p].item()]\n",
    "\n",
    "    plt.bar([\"P1\", \"P1'\", \"P2\", \"P2'\", \"P3\", \"P3'\", \"P4\", \"P4'\"], heights, color=[('b', 1.), ('b', 0.4), ('b', 1.), ('b', 0.4), ('b', 1.), ('b', 0.4), ('b', 1.), ('b', 0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f5434-79ee-4d51-88d9-4d6da932e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(lo_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696aa58-138e-4a05-ae55-71e4ab3f4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(go_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea8b92-1418-4e5e-8067-858aa203e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(rndctrl_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d91f9f-8c05-4f2c-a6b1-ae9514eee5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(seqctrl_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471227b-4555-463f-b22c-66ca54eeaa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ephys] *",
   "language": "python",
   "name": "conda-env-ephys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
